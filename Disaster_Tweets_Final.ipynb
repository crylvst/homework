{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8524c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7108ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для очистки текстов\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_not_ASCII(text):\n",
    "    text = ''.join([word for word in text if word in string.printable])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c3a423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для лемматизации\n",
    "\n",
    "mystem = Mystem()\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in english_stopwords \\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a53dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "df_train = pd.read_csv('C:/Users/hp/nlp-getting-started/train.csv')\n",
    "df_test = pd.read_csv('C:/Users/hp/nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a922382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-fbe5242ce238>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['text'] = df_train['text'].str.replace('\\d+', '')\n",
      "<ipython-input-5-fbe5242ce238>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['text'] = df_train['text'].str.replace('https?://\\S+|www\\.\\S+', '')\n",
      "<ipython-input-5-fbe5242ce238>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['text'] = df_train['text'].str.replace('\\w*\\@\\w*', '')\n",
      "<ipython-input-5-fbe5242ce238>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['text'] = df_train['text'].str.replace('<.*?>', '')\n",
      "<ipython-input-5-fbe5242ce238>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['text'] = df_train['text'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "# очищение текстов\n",
    "\n",
    "for text in df_train['text']:\n",
    "    df_train['text'] = df_train['text'].str.replace('\\d+', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('https?://\\S+|www\\.\\S+', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('\\w*\\@\\w*', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('<.*?>', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('[^\\w\\s]', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('#', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('\\n', '')\n",
    "    df_train['text'] = df_train['text'].str.replace('_', ' ')\n",
    "    df_train['text'] = df_train['text'].str.replace('  ', ' ')\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_emoji(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_not_ASCII(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971b06cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Working at zumiez is the which location'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[1069]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e095d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-39d5388f6c97>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['text'] = df_test['text'].str.replace('\\d+', '')\n",
      "<ipython-input-9-39d5388f6c97>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['text'] = df_test['text'].str.replace('https?://\\S+|www\\.\\S+', '')\n",
      "<ipython-input-9-39d5388f6c97>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['text'] = df_test['text'].str.replace('\\w*\\@\\w*', '')\n",
      "<ipython-input-9-39d5388f6c97>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['text'] = df_test['text'].str.replace('<.*?>', '')\n",
      "<ipython-input-9-39d5388f6c97>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['text'] = df_test['text'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "# очищение текстов из тестовой выборки\n",
    "for text in df_test['text']:\n",
    "    df_test['text'] = df_test['text'].str.replace('\\d+', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('https?://\\S+|www\\.\\S+', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('\\w*\\@\\w*', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('<.*?>', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('[^\\w\\s]', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('#', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('\\n', '')\n",
    "    df_test['text'] = df_test['text'].str.replace('_', ' ')\n",
    "    df_test['text'] = df_test['text'].str.replace('  ', ' ')\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_emoji(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_not_ASCII(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4f3d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latest Suresh Prabhu calls Harda derailment a natural calamity officials feel Economic Ti IndianNews'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[1069]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1a0d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# лемматизация\n",
    "df_train[\"text\"] = df_train[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "596dadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# лемматизация\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d05f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранила чистые тексты в отдельные csv, снова их подгружаю\n",
    "df_train_clean = pd.read_csv('C:/Users/hp/twitter_df_train_clean.csv')\n",
    "df_test_clean = pd.read_csv('C:/Users/hp/twitter_df_test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b99e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнение NaN в тестовой выборке\n",
    "df_test_clean['text'] = df_test_clean['text'].fillna('nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f510a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "text          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_clean.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a52867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизация\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "train_tfidf_vec = vec.fit(df_train_clean['text'])  \n",
    "test_tfidf_vec = vec.fit(df_test_clean['text'])\n",
    "\n",
    "vec_train = train_tfidf_vec.transform(df_train_clean['text'])\n",
    "vec_test = test_tfidf_vec.transform(df_test_clean['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d78a72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train embedded vector is (7613, 8940)\n",
      "Shape of the test embedded vector is (3263, 8940)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the train embedded vector is {}\".format(vec_train.shape))\n",
    "print(\"Shape of the test embedded vector is {}\".format(vec_test.shape))\n",
    "# ура, оно работает!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d1926df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vec_train\n",
    "y = df_train_clean['target']\n",
    "z = vec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c54f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# наивный Байес\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "mnb = MultinomialNB(alpha=1).fit(x, y)\n",
    "predicted_mnb = mnb.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55230996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=107, min_samples_split=5, min_samples_leaf=1, max_depth=None)\n",
    "\n",
    "rfc.fit(x, y)\n",
    "predicted_rfc = rfc.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d87d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод К-ближайших соседей\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x, y)\n",
    "predicted_knn = knn.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daa6680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод опорных векторов\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=2)\n",
    "svc.fit(x, y)\n",
    "predicted_svc = svc.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b4edf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:50:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier (learning_rate=0.02, n_estimators=600, subsample=0.6, min_child_weight=1, max_depth=40, gamma=1, colsample_bytree=1.0)\n",
    "xgb_model.fit(x, y)\n",
    "predicted_xgb = xgb_model.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be3a4650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:51:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:53:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:53:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:53:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:54:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:54:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# стекинг моделей\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    (\"mnb\", mnb),\n",
    "    (\"rfc\", rfc),\n",
    "    (\"knn\", knn),\n",
    "    (\"svc\", svc),\n",
    "    (\"xgb\", xgb_model)\n",
    "]\n",
    "\n",
    "sc = StackingClassifier(estimators=estimators,cv=5)\n",
    "\n",
    "sc.fit(x, y)\n",
    "predicted_sc = sc.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f801c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение результата\n",
    "result = pd.read_csv(\"C:/Users/hp/sample_submission.csv\")\n",
    "result['target'] = predicted_sc\n",
    "result.to_csv('disastaer_tweets_staking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7929a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.79160\n",
    "# 0.79803"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
